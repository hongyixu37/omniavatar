<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis">
  <meta property="og:title" content="OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis"/>
  <meta property="og:description" content="A controllable 3D-aware image synthesis network with disentangled semantic control over camera pose, head shape and facial expression, including neck and jaw articulations. "/>
  <meta property="og:url" content="https://hongyixu37.github.io/omniavatar/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="GAN, controllable, expression, head pose">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://hongyixu37.github.io/homepage/" target="_blank">Hongyi Xu</a>,</span>
                <span class="author-block">
                  <a href="https://guoxiansong.github.io/homepage/index.html" target="_blank">Guoxian Song</a>,</span>
                  <span class="author-block">
                    <a href="https://zihangjiang.github.io/" target="_blank">Zihang Jiang</a>,</span>
                  <span class="author-block">
                    <a href="http://jeff95.me/" target="_blank">Jianfeng Zhang</a>,</span>
                  <span class="author-block">
                    <a href="https://seasonsh.github.io/" target="_blank">Yichun Shi</a>,</span>
                  <br>
                  <span class="author-block">
                    <a href="https://www.jingliu.net/" target="_blank">Jing Liu</a>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=VBpzuo4AAAAJ&hl=en" target="_blank">Wanchun Ma</a>,</span>
                  <span class="author-block">
                      <a href="https://sites.google.com/site/jshfeng/home" target="_blank">Jiashi Feng</a>,</span>                  
                  <span class="author-block">
                    <a href="http://linjieluo.com/" target="_blank">Linjie Luo</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">ByteDance Inc,        National University of Singapore<br>CVPR 2023</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                    <span class="link-block">
                        <a href="https://arxiv.org/abs/2303.15539" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                  <span class="link-block">
                      <a href="static/pdfs/supplementary.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Supplementary Video link -->
                  <span class="link-block">
                    <a href="https://www.youtube.com/watch?v=Z1aXE9q9eUI" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-youtube fa-w-18" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="youtube" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg>
                      <!-- <i class="fas fa-youtube"></i> -->
                    </span>
                    <span>Video</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/hongyixu37/omniavatar-proj" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://hongyixu37.github.io/omniavatar" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/intro.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        We present OmniAvatar, a controllable 3D-aware image synthesis network with disentangled control over camera pose, head shape and facial expression, including neck and jaw articulations.  
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present OmniAvatar, a novel geometry-guided 3D head synthesis model trained from in-the-wild unstructured images that is capable of synthesizing diverse identity-preserved 3D heads with compelling dynamic details under full disentangled control over camera poses, facial expressions, head shapes, articulated neck and jaw poses. To achieve such high level of disentangled control, we first explicitly define a novel semantic signed distance function (SDF) around a head geometry (FLAME) conditioned on the control parameters. This semantic SDF allows us to build a differentiable volumetric correspondence map from the observation space to a disentangled canonical space from all the control parameters. We then leverage the 3D-aware GAN framework (EG3D) to synthesize detailed shape and appearance of 3D full heads in the canonical space, followed by a volume rendering step guided by the volumetric correspondence map to output into the observation space. To ensure the control accuracy on the synthesized head shapes and expressions, we introduce a geometry prior loss to conform to head SDF and a control loss to conform to the expression code. Further, we enhance the temporal realism with dynamic details conditioned upon varying expressions and joint poses. Our model can synthesize more preferable identity-preserved 3D heads with compelling dynamic details compared to the state-of-the-art methods both qualitatively and quantitatively. We also provide an ablation study to justify many of our system design choices.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper Pipeline -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Pipeline</h2>
      <img src="static/images/pipeline.png" alt="MY ALT TEXT"/>
      <h4 class="content has-text-justified">
        <b>Stage I</b>: Trained from parameterized FLAME mesh collections, a MLP-network W maps a shape α, expression θ and articulated jaw and neck pose θ into 3D point-to-point volumetric correspondences from observation
        to canonical space, together with a signed distance function of the corresponding FLAME head. <b>Stage II</b>: Given a Gaussian latent code z,
        our model generates a tri-plane represented 3D feature space of a canonical head, disentangled with shape and expression controls. The
        volume rendering is then guided by the volumetric correspondence field to map the decoded neural radiance field from the canonical to
        observation space. We condition the NeRF decoding with expression and joint pose for modeling dynamic details. A super-resolution
        module synthesizes the final high-resolution RGB image from the volume-rendered feature map. For fine-grained shape and expression
        control, we apply the FLAME SDF as geometric prior to the synthesized NeRF density, and self-supervise the image synthesis to commit
        to the target expression β and joint pose θ by comparing the input code against the re-estimated values \hat{β}, \hat{θ} from synthesized images.
      </h4>
      </div>
    </div>
  </section>
<!--End paper poster -->






<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://youtube.com/watch?v=Z1aXE9q9eUI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <!-- <div class="item">
          <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
            First image description.
          </h2>
        </div> -->
        <div class="item item-video1">
          <video poster="animation" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/animation1.mp4"
            type="video/mp4", alt="Talking Head Generation">
          </h2>
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/face_reenactment1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/face_reenactment2.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <img src="static/images/poster.png" alt="MY ALT TEXT"/>
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@InProceedings{Xu_2023_CVPR_OmniAvatar,
        author    = {Xu, Hongyi and Guoxian Song and Zihang Jiang and Jianfeng Zhang and Yichun Shi and Jing Liu and Wanchun Ma and Jiashi Feng and Linjie Luo},
        title     = {OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        month     = {June},
        year      = {2023},
        pages     = {12814-12824}
    }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
